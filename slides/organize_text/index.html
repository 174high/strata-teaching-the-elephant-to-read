<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>Teaching the Elephant to Read- Organizing Corpora</title>

    <meta name="author" content="Benjamin Bengfort">
    <meta name="keywords" content="NLP, NLTK, Natural Language Processing, Computational Lingustics">
    <meta name="description" content="An introduction to NLP and NLTK">

    <link rel="shortcut icon" href="../favicon.png">

    <!-- CSS : implied media="all" -->
    <link rel="stylesheet" type="text/css" href="../css/reveal.min.css" />
    <link rel="stylesheet" type="text/css" href="../css/theme/default.css" />
    <link rel="stylesheet" type="text/css" href="../lib/css/zenburn.css" />

</head>
<body>

    <div class="reveal">
        <div class="slides">
            <section data-markdown>
                <script type="text/template">
                    # Organizing Text #
                    The management of large bodies of natural language - corpora
                </script>
            </section>
            <section>
                <section data-markdown>
                    <script type="text/template">
                        ## Some Built In Corpora ##
                        All can be found in `nltk.corpus`

                        * <strong>`gutenberg`: Small selection of literature</strong>
                        * <strong class="color:red">`shakespeare`: For Elizabethan comparisons</strong>
                        * `brown`: First million word electronic corpus
                        * `webtext`: Forums, personal ads, movie script, reviews
                        * `nps_chat`: Chat text collectd by Naval Postgrad School
                        * `reuters`: News articles (1.3 million words)
                        * `inaugural`: Innaugural addresses
                        * `swtichboard`: Transcribed phone conversations

                    </script>
                </section>
                <section data-markdown>
                    <script type="text/template">
                        ## BIG Corpora ##

                        * Google 5-gram corpus: 24GB compressed 1 trillion words
                        * USENET Corpus: 25 B words 28 GB compressed
                        * UkWaC - 88 million sentences 5.1 GB compressed (tagged)
                        * Stack Overflow - last month of questions


                        ** All available via Bit Torrent **
                    </script>
                </section>
                <section data-markdown>
                    <script type="text/template">
                        [![Gunny Approved][gunny.jpg]][gunny.jpg]

                        > This is my corpus <br />
                        > There are many like it <br />
                        > But this one is mine.

                        [gunny.jpg]: <../img/task_one/gunny.jpg> "Gunny Approved"
                    </script>
                </section>
            </section>
            <section>
                <section data-markdown>
                    <script type="text/template">
                        ## Organizing your own corpus ##

                            |-- Corpus Root
                            +--+
                               |-- README
                               |-- categories.txt
                               |-- texta.txt
                               +-- textb.txt

                        * NLTK Corpus Organization works with HDFS
                        * Use a container to ensure files are 64MB
                        * Directory hierarchy for classifiers.

                    </script>
                </section>
            </section>
            <section>
                <section data-markdown>
                    <script type="text/template">
                        ## Beyond Plaintext ##

                        * Tagged and Categoried Corpora
                        * HTML - `nltk.clean_html` or `BeautifulSoup`
                        * RSS - `feedparser` library
                        * PDF - `pypdf`
                        * MS Word - `pywin23`

                    </script>
                </section>
                <section data-markdown>
                    <script type="text/template">
                        ## A Note on Encoding ##

                        * We are going to get away with UTF-8
                        * But encoding is HARD
                        * NLTK has stuff to handle it for you
                        * But always be thinking about it!

                    </script>
                </section>
            </section>
            <section>
                <section data-markdown>
                    <script type="text/template">
                        # STOP, Tutorial Time #

                        * Vocabulary & Lexical Diversity
                    </script>
                </section>
            </section>

            <section>
                <section data-markdown>
                    <script type="text/template">
                        ## Vocabulary ##

                        Vocabulary is the set of unique words.

                        Lexical Diversity is how rich the lexicon is in a text.

                            from nltk.tokenize import wordpunct_tokenize

                            class VocabularyMapper(object):

                                def __call__(self, key, value):
                                    for word in self.tokenize(value):
                                            yield word, 1

                                def normalize(self, word):
                                    return word.lower()

                                def tokenize(self, sentence):
                                    for word in wordpunct_tokenize(sentence):
                                        yield self.normalize(word)


                    </script>
                </section>
               <section data-markdown>
                    <script type="text/template">
                        ## Lexical Diversity ##

                        Vocabulary is the set of unique words.

                        Lexical Diversity is how rich the lexicon is in a text.

                            from __future__ import division

                            class LexicalDiversityReducer(object):

                                def __init__(self):
                                    self.vocab  = 0
                                    self.tokens = 0

                                def __call__(self, key, values):
                                    self.vocab += 1
                                    self.tokens += sum(values)
                                    lexdiv = self.tokens / self.vocab
                                    yield 1, (self.vocab, self.tokens, lexdiv)

                    </script>
                </section>
            </section>
            <section>
                <section data-markdown>
                    <script type="text/template">
                        ## Frequency Distributions ##
                        Lets add some basic statistics with NLTK built-in
                        data structures. FreqDist is _often used_!

                            from nltk import FreqDist

                            class MyCorpus(PlaintextCorpusReader):

                                def histogram(self):
                                    return FreqDist(self.text())

                        Note that the FreqDist will also give you vocabulary and length.
                    </script>
                </section>
            </section>
            <section>
                <section data-markdown>
                    <script type="text/template">
                        ## Conditional Frequency Distributions ##
                        This helper data structure holds a set of
                        FreqDists for conditions.

                            import nltk

                            names  = nltk.corpus.names
                            male   = names.words('male.txt')
                            female = names.words('female.txt')

                            distr  = nltk.ConditionalFreqDist(
                                        (fileid, name[-1])
                                        for fileid in name.fileids()
                                        for name in names.words(fileid)
                                     )
                            distr.plot()

                        Note: drawing and graphing might require additional libraries,
                        particularly `python-tkinter` and `python-matplotlib`

                    </script>
                </section>
            </section>
            <section>
                <section data-markdown>
                    <script type="text/template">
                        ## On to Some Actual Big Data NLP ##

                        [Back to Main Page](../index.html)

                    </script>
                </section>
            </section>
        </div>
    </div>

    <!-- Javascript at the bottom of the page for faster loading -->
    <script type="text/javascript" src="../lib/js/head.min.js"></script>
    <script type="text/javascript" src="../js/reveal.min.js"></script>
    <script type="text/javascript">
        Reveal.initialize({
            controls: true,
            progress: true,
            history:  false,
            keyboard: true,
            touch:    false,
            overview: true,
            center:   true,
            loop:     false,
            transition: 'default',
            transitionSpeed: 'default',
            backgroundTransition: 'default',
            dependencies: [
                // Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
                { src: '../lib/js/classList.js', condition: function() { return !document.body.classList; } },

                // Interpret Markdown in <section> elements
                { src: '../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: '../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

                // Syntax highlight for <code> elements
                { src: '../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },

                // Zoom in and out with Alt+click
                { src: '../plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
            ]
        });
    </script>

</body>
</html>
